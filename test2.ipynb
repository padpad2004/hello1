{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from bs4 import BeautifulSoup\n",
    "from scipy.interpolate import make_interp_spline\n",
    "import requests\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the base url which i can use as a base and add the dates to so i can access the different pages\n",
    "base_url = \"https://www.transfermarkt.co.uk/premier-league/marktwerteverein/wettbewerb/GB1/stichtag/\"\n",
    "\n",
    "# Dictionary to store DataFrames for each date\n",
    "dfs_prem_value = {}\n",
    "\n",
    "# Custom headers to mimic a real browser\n",
    "headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:109.0) Gecko/20100101 Firefox/109.0\",\n",
    "    \"Accept-Language\": \"en-US,en;q=0.5\"\n",
    "}\n",
    "\n",
    "# Loop through each year from 2011 to 2024\n",
    "for year in range(2011, 2025):\n",
    "    date_str = f\"{year}-03-15\"\n",
    "    url = base_url + date_str \n",
    "    print(f\"Scraping: {url}\")\n",
    "    \n",
    "    response = requests.get(url, headers=headers)\n",
    "    if response.status_code != 200:\n",
    "        print(f\"Error fetching page for {date_str}: {response.status_code}\")\n",
    "        continue\n",
    "\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    \n",
    "    # First, try to find the table with class \"items\"\n",
    "    table = soup.find('table', class_=\"items\")\n",
    "    \n",
    "    # If not found, look inside HTML comments\n",
    "    if not table:\n",
    "        comments = soup.find_all(string=lambda text: isinstance(text, Comment))\n",
    "        for comment in comments:\n",
    "            comment_soup = BeautifulSoup(comment, \"html.parser\")\n",
    "            table = comment_soup.find('table', class_=\"items\")\n",
    "            if table:\n",
    "                break\n",
    "\n",
    "    if table:\n",
    "        try:\n",
    "            df = pd.read_html(str(table))[0]\n",
    "            dfs_prem_value[date_str] = df\n",
    "            print(f\"Found items table for {date_str} with {len(df)} rows.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error parsing table for {date_str}: {e}\")\n",
    "    else:\n",
    "        print(f\"No items table found for {date_str}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a regex pattern_top6 matching the desired club names in lower-case\n",
    "pattern_top6 = r'manchester city|manchester united|chelsea fc|tottenham hotspur|liverpool fc|arsenal fc'\n",
    "pattern_bottom6 = r'southampton fc|leicester city|ipswich town|fulham fc|everton fc|wolverhampton wanderers'\n",
    "\n",
    "# Dictionary to store the filtered DataFrames\n",
    "filtered_dataframes_top_6 = {}\n",
    "\n",
    "# Loop through each date and DataFrame in the scraped data\n",
    "for date, df in dfs.items():\n",
    "    # Check that the expected column is present\n",
    "    if 'Club' in df.columns:\n",
    "        # Filter rows by matching the pattern_top6 in a case-insensitive manner.\n",
    "        filtered_df_top = df[df['Club'].str.lower().str.contains(pattern_top6, na=False)]\n",
    "        filtered_dataframes_top_6[date] = filtered_df_top\n",
    "        print(f\"{date}: {len(filtered_df_top)} rows retained.\")\n",
    "    else:\n",
    "        print(f\"DataFrame for {date} does not contain a 'Club' column. Available columns: {df.columns}\")\n",
    "\n",
    "\n",
    "# Dictionary to store the filtered DataFrames\n",
    "filtered_dataframes_bottom_6 = {}\n",
    "\n",
    "# Loop through each date and DataFrame in your scraped data\n",
    "for date, df in dfs.items():\n",
    "    # Check that the expected column is present\n",
    "    if 'Club' in df.columns:\n",
    "        # Filter rows by matching the pattern_top6 in a case-insensitive manner.\n",
    "        filtered_df_bottom = df[df['Club'].str.lower().str.contains(pattern_bottom6, na=False)]\n",
    "        filtered_dataframes_bottom_6[date] = filtered_df_bottom\n",
    "        print(f\"{date}: {len(filtered_df_bottom)} rows retained.\")\n",
    "    else:\n",
    "        print(f\"DataFrame for {date} does not contain a 'Club' column. Available columns: {df.columns}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_dataframes_top_6['2022-03-15']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_dataframes_bottom_6['2022-03-15']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of column names to drop\n",
    "columns_to_drop = ['#', 'wappen', 'Club.1', 'Current value', '%', 'Unnamed: 8','Unnamed: 9' ]  # Replace with your actual column names\n",
    "\n",
    "# Loop through each DataFrame in your dictionary (e.g., filtered_dataframes)\n",
    "for date, df in filtered_dataframes_top_6.items():\n",
    "    # Drop the columns and update the DataFrame in the dictionary\n",
    "    # Using errors='ignore' ensures that if a column is missing, it won't raise an error\n",
    "    filtered_dataframes_top_6[date] = df.drop(columns=columns_to_drop, errors='ignore')\n",
    "\n",
    "for date, df in filtered_dataframes_bottom_6.items():\n",
    "    # Drop the columns and update the DataFrame in the dictionary\n",
    "    # Using errors='ignore' ensures that if a column is missing, it won't raise an error\n",
    "    filtered_dataframes_bottom_6[date] = df.drop(columns=columns_to_drop, errors='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming your dictionary of DataFrames is called 'filtered_dataframes'\n",
    "for date, df in filtered_dataframes_top_6.items():\n",
    "    # Check if the column 'League' exists and then rename it to the date\n",
    "    if 'League' in df.columns:\n",
    "        df.rename(columns={'League': \"Value_\" + date}, inplace=True)\n",
    "    else:\n",
    "        print(f\"'League' column not found in DataFrame for {date}\")\n",
    "\n",
    "for date, df in filtered_dataframes_bottom_6.items():\n",
    "    # Check if the column 'League' exists and then rename it to the date\n",
    "    if 'League' in df.columns:\n",
    "        df.rename(columns={'League': \"Value_\" + date}, inplace=True)\n",
    "    else:\n",
    "        print(f\"'League' column not found in DataFrame for {date}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_dataframes_top_6['2014-03-15'].head(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_dataframes_bottom_6['2014-03-15'].head(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New dictionary to store the subset DataFrames\n",
    "filtered_dataframes_top_6_v1 = {}\n",
    "\n",
    "for date, df in filtered_dataframes_top_6.items():\n",
    "    # Construct the value column name based on the date\n",
    "    value_col = \"Value_\" + date\n",
    "    if 'Club' in df.columns and value_col in df.columns:\n",
    "        # Select only the 'Club' and the 'Value_(date)' columns\n",
    "        subset_df = df[['Club', value_col]].copy()\n",
    "        filtered_dataframes_top_6_v1[date] = subset_df\n",
    "        print(f\"For {date}: Retained columns: {subset_df.columns.tolist()}\")\n",
    "    else:\n",
    "        print(f\"DataFrame for {date} does not have the required columns: 'Club' and {value_col}\")\n",
    "\n",
    "filtered_dataframes_bottom_6_v1 = {}\n",
    "\n",
    "for date, df in filtered_dataframes_bottom_6.items():\n",
    "    # Construct the value column name based on the date\n",
    "    value_col = \"Value_\" + date\n",
    "    if 'Club' in df.columns and value_col in df.columns:\n",
    "        # Select only the 'Club' and the 'Value_(date)' columns\n",
    "        subset_df = df[['Club', value_col]].copy()\n",
    "        filtered_dataframes_bottom_6_v1[date] = subset_df\n",
    "        print(f\"For {date}: Retained columns: {subset_df.columns.tolist()}\")\n",
    "    else:\n",
    "        print(f\"DataFrame for {date} does not have the required columns: 'Club' and {value_col}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_dataframes_top_6_v1['2017-03-15'].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_dataframes_bottom_6_v1['2017-03-15'].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start with an empty combined dataframe\n",
    "combined_df_top6 = None\n",
    "combined_df_bottom6 = None\n",
    "\n",
    "# Loop through each date and merge on the 'Club' column\n",
    "for date, df in filtered_dataframes_top_6_v1.items():\n",
    "    if combined_df_top6 is None:\n",
    "        combined_df_top6 = df\n",
    "    else:\n",
    "        combined_df_top6 = pd.merge(combined_df_top6, df, on='Club', how='outer')\n",
    "\n",
    "# Display the first few rows of the combined dataframe\n",
    "print(combined_df_top6.head())\n",
    "\n",
    "for date, df in filtered_dataframes_bottom_6_v1.items():\n",
    "    if combined_df_bottom6 is None:\n",
    "        combined_df_bottom6 = df\n",
    "    else:    \n",
    "        combined_df_bottom6 = pd.merge(combined_df_bottom6, df, on='Club', how='outer') \n",
    "print(combined_df_bottom6.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def convert_value(value_str):\n",
    "    \"\"\"\n",
    "    Convert a monetary string (e.g., \"€310.75m\", \"€1.19bn\") into a numeric value.\n",
    "    \"\"\"\n",
    "    if isinstance(value_str, str):\n",
    "        # Remove the euro symbol and extra spaces, then convert to lower case\n",
    "        value_str = value_str.replace(\"€\", \"\").strip().lower()\n",
    "        if \"m\" in value_str:\n",
    "            try:\n",
    "                # Remove \"m\", convert to float, and multiply by 1e6\n",
    "                return float(value_str.replace(\"m\", \"\")) * 1_000_000\n",
    "            except:\n",
    "                return None\n",
    "        elif \"bn\" in value_str:\n",
    "            try:\n",
    "                # Remove \"bn\", convert to float, and multiply by 1e9\n",
    "                return float(value_str.replace(\"bn\", \"\")) * 1_000_000_000\n",
    "            except:\n",
    "                return None\n",
    "        else:\n",
    "            try:\n",
    "                return float(value_str)\n",
    "            except:\n",
    "                return None\n",
    "    return value_str\n",
    "\n",
    "# Assuming your combined dataframe is named 'combined_df_top6'\n",
    "# Loop through all columns and apply conversion on columns that start with \"Value_\"\n",
    "for col in combined_df_top6.columns:\n",
    "    if col.startswith(\"Value_\"):\n",
    "        combined_df_top6[col] = combined_df_top6[col].apply(convert_value)\n",
    "\n",
    "for col in combined_df_bottom6.columns:\n",
    "    if col.startswith(\"Value_\"):\n",
    "        combined_df_bottom6[col] = combined_df_bottom6[col].apply(convert_value)  \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_transposed_top6 = combined_df_top6.set_index('Club').transpose()\n",
    "\n",
    "# Remove the \"Value_\" prefix from the index and convert to datetime objects.\n",
    "df_transposed_top6.index = pd.to_datetime(df_transposed_top6.index.str.replace(\"Value_\", \"\", regex=True))\n",
    "df_transposed_top6 = df_transposed_top6.sort_index()\n",
    "\n",
    "df_transposed_bottom6 = combined_df_bottom6.set_index('Club').transpose()\n",
    "\n",
    "# Remove the \"Value_\" prefix from the index and convert to datetime objects.\n",
    "df_transposed_bottom6.index = pd.to_datetime(df_transposed_bottom6.index.str.replace(\"Value_\", \"\", regex=True))\n",
    "df_transposed_bottom6 = df_transposed_bottom6.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import matplotlib.ticker as ticker\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from scipy.interpolate import make_interp_spline\n",
    "\n",
    "# ---------------------- Custom Y-Axis Formatter ---------------------- #\n",
    "def custom_y_formatter(x, pos):\n",
    "    if x < 1e9:\n",
    "        return f\"{x/1e6:,.0f} million\"\n",
    "    else:\n",
    "        return f\"{x/1e9:,.1f} billion\"\n",
    "\n",
    "# Set Seaborn style and palette for aesthetics.\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_palette(\"Set2\")\n",
    "\n",
    "# Create a figure with 2 subplots (vertical layout).\n",
    "fig, axes = plt.subplots(nrows=2, ncols=1, figsize=(12, 10), sharex=True)\n",
    "\n",
    "# ---------------------- Plotting Function ---------------------- #\n",
    "def plot_data(ax, df_transposed, title):\n",
    "    # Convert datetime index to numeric for spline interpolation.\n",
    "    x_dates = mdates.date2num(df_transposed.index.to_pydatetime())\n",
    "    \n",
    "    # Plot each club's data.\n",
    "    for club in df_transposed.columns:\n",
    "        y = df_transposed[club].values\n",
    "        if len(x_dates) >= 3:\n",
    "            spline = make_interp_spline(x_dates, y, k=3)  # Cubic spline for smoothness.\n",
    "            x_dense = np.linspace(x_dates.min(), x_dates.max(), 300)\n",
    "            y_smooth = spline(x_dense)\n",
    "            x_dense_dates = mdates.num2date(x_dense)\n",
    "            ax.plot(x_dense_dates, y_smooth, label=club, linewidth=2)\n",
    "        else:\n",
    "            ax.plot(df_transposed.index, y, marker='o', label=club, linewidth=2)\n",
    "    \n",
    "    # Format the x-axis: one tick per year, display only the year.\n",
    "    ax.xaxis.set_major_locator(mdates.YearLocator())\n",
    "    ax.xaxis.set_major_formatter(mdates.DateFormatter('%Y'))\n",
    "    ax.tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    # Disable scientific notation/offsets on the y-axis.\n",
    "    ax.ticklabel_format(axis='y', style='plain', useOffset=False)\n",
    "    ax.get_yaxis().get_major_formatter().set_scientific(False)\n",
    "    \n",
    "    # Limit the number of y-axis ticks.\n",
    "    ax.yaxis.set_major_locator(ticker.MaxNLocator(6))\n",
    "    \n",
    "    # Apply the custom y-axis formatter.\n",
    "    ax.yaxis.set_major_formatter(ticker.FuncFormatter(custom_y_formatter))\n",
    "    \n",
    "    # Set titles and labels.\n",
    "    ax.set_title(title, fontsize=14, fontweight='bold')\n",
    "    ax.set_xlabel(\"Year\", fontsize=12)\n",
    "    ax.set_ylabel(\"Investment Value\", fontsize=12)\n",
    "    ax.legend(loc='upper left', bbox_to_anchor=(1.02, 1), borderaxespad=0)\n",
    "\n",
    "# ---------------------- Plot for Top 6 Teams ---------------------- #\n",
    "plot_data(axes[0], df_transposed_top6, \"Top 6 Teams Values Over Time (2011-2024)\")\n",
    "\n",
    "# ---------------------- Plot for Bottom 6 Teams ---------------------- #\n",
    "plot_data(axes[1], df_transposed_bottom6, \"Bottom 6 Teams Values Over Time (2011-2024)\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
